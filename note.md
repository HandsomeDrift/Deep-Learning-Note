# 深度学习笔记

## 符号

### 字体

**正常**

$x$

$X$

**Bbb**

$\Bbb{x}$

$\Bbb{X}$

**mathbb**

$\mathbb{x}$

$\mathbb{X}$

**mathbf**

$\mathbf{x}$

$\mathbf{X}$

**mathtt**

$\mathtt{x}$

$\mathtt{X}$

**mathrm**

$\mathrm{x}$

$\mathrm{X}$

**mathsf**

$\mathsf{x}$

$\mathsf{X}$

**mathcal**

$\mathcal{x}$

$\mathcal{X}$

**mathscr**
$\mathscr{x}$

$\mathscr{X}$

**mathfrak**

$\mathfrak{x}$

$\mathfrak{X}$

### 数字

标量 $x$ 

向量 $\mathbf{x}$

矩阵 $\mathbf{X}$

张量 $\mathsf{X}$

单位矩阵  $\mathbf{I}$

### 集合

集合 $\mathcal{X}$

整数集合 $\mathbb{Z}$

实数集合 $\mathbb{R}, \mathbb{R}^n, \mathbb{R}^{a \times b}$

### 函数和运算符

按元素相乘 $\odot$

集合的基数 $|\mathcal{X}|$

$L_p$正则 $\Vert \cdot \Vert_p$

$L_2$正则 $\Vert \cdot \Vert$

向量点积 $\langle \mathbf{x}, \mathbf{y} \rangle$

定义 $\triangleq$

### 微积分

导数 $\text{d}$

偏导 $\partial$

梯度 $\nabla$

积分 $\int$

### 概率论与信息论

随机变量$z$具有概率分布$P$ $z$~$P$

变量独立 $X \bot Y$

方差 $\text{Var}$

随机变量的相关性 $\rho(X, Y)$

熵 $H$

$P$和$Q$的KL-散度 $D_{KL}(P \Vert Q)$

## 引言

 任一调整参数后的程序被称为*模型*（model）。 通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。 使用数据集来选择参数的元程序被称为*学习算法*（learning algorithm）。

### 机器学习中的关键组件

无论什么类型的机器学习问题，都会遇到这些组件：

1. 可以用来学习的*数据*（data）；
2. 如何转换数据的*模型*（model）；
3. 一个*目标函数*（objective function），用来量化模型的有效性；
4. 调整模型参数以优化目标函数的*算法*（algorithm）。

 #### 数据

 每个数据集由一个个*样本*（example, sample）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。 样本有时也叫做*数据点*（data point）或者*数据实例*（data instance），通常每个样本由一组称为*特征*（features，或*协变量*（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为*标签*（label，或*目标*（target））。

当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的*维数*（dimensionality）。 

 与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。

#### 目标函数

 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为*损失函数*（loss function，或cost function）。

 在一个数据集上，我们可以通过最小化总损失来学习模型参数的最佳值。 该数据集由一些为训练而收集的样本组成，称为*训练数据集*（training dataset，或称为*训练集*（training set））。 然而，在训练数据上表现良好的模型，并不一定在“新数据集”上有同样的性能，这里的“新数据集”通常称为*测试数据集*（test dataset，或称为*测试集*（test set））。

#### 优化算法

 深度学习中，大多流行的优化算法通常基于一种基本方法–*梯度下降*（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。  然后，它在可以减少损失的方向上优化参数。

### 机器学习问题

#### 监督学习

*监督学习*（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个*样本*（example）。 

目标是生成一个模型，能够将任何输入特征映射到标签（即预测）。

用概率论术语来说，我们希望预测“估计给定输入特征的标签”的条件概率。 

监督学习的==学习过程==一般可以分为三大步骤：

1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。这些输入和相应的标签一起构成了训练数据集；
2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测。

![image-20240909192038311](note.assets/image-20240909192038311.png)

 ##### 回归

*回归*（regression）是最简单的监督学习任务之一。当标签取任意数值时，我们称之为*回归*问题，此时的目标是生成一个模型，使它的预测非常接近实际标签值。

判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题。比如：

- 这个手术需要多少小时；
- 在未来6小时，这个镇会有多少降雨量。
